# MITFutureMakers
SureStart X MIT RAISE


## Breakdown
#### Week 1: The Basics
##### [Day 1: Tuesday, July 6, 2021: Welcome to SureStart! (Getting Started)](#Day1)
##### [Day 2: Wednesday, July 7, 2021: Become a Leader!](#Day2)
##### [Day 3: Thursday, July 8, 2021: Introduction to Machine Learning and Scikit-Learn](#Day3)
##### [Day 4: Friday, July 9, 2021: What is Deep Learning?](#Day4)
##### [Day 5-6: Saturday, July 10-Sunday, July 11, 2021: Weekend](#Day5/6)
#### Week 2: CNNs, Data, & Machine Learning
##### [Day 7: Monday, July 12, 2021: Introduction to ML and TensorFlow](#Day7)
##### [Day 8: Tuesday, July 13, 2021: What are Neural Networks (NN)?](#Day8)

<a name = "Day1"></a>
## Day 1: Tuesday, July 6, 2021: Welcome to SureStart! (Getting Started)
### Objectives:
1. To get comfortable with the following languages, libraries, and spaces: Python, NumPy, and Github
2. To begin building a technical profile on Github

### Lesson Plan:
1. [MIT FutureMakers Create-a-thon Ramp-Up](https://static1.squarespace.com/static/5f45536caa356e6ab51588f4/t/60c5f9d1311d375de93595e6/1623587288184/MIT+FutureMakers+Ramp+Up.pdf)

### Workshops & Key Learnings:
#### Program Kick-Off:
- [MIT RAISE](raise.mit.edu): a K-12 AI Education initiative @ the Massachusetts Institute of Technology
- With today's information technology, young people have opportunities to create impact on their lives and on their communities --> FutureMakers take Computational Action
- Program Outcome: new tech and "power" skills, a repo of code or app samples, a video of final Create-a-thon Presentation, and more confidence and interest in AI
- Applied Deep Learning Track: learning period from July 6, 2021 to July 30, 2021, and Create-a-thon from August 2, 2021 to August 13, 2021
#### Deep Learning Overview with Head Mentors
- Learned about Python and NumPy in relation to Deep Learning (i.e. list iteration, indexing, broadcasting, etc.
- Jupyter Notebook & Colab Notebook Demos
#### STEM + Computing Reflection Corner for All
- How an interest in computing correlate to different STEM fields and careers
- Not only do the fields utilize logical approaches, they also require creative problem-solving skills and have the power to create something good for our society

### Action Item(s):
1. DAY 1 REFLECTION: I am excited to learn more about AI technology and how to apply this knowledge to help improve the lives of specific demographics of people around me by implementing Deep Learning within my projects. I hope that through the program, I am able to use my passion for Computer Science for societal good.


<a name = "Day2"></a>
## Day 2: Wednesday, July 7, 2021: Become a Leader!
### Objectives:
1. To develop the skills, mindset, and vision of a leader

### Lesson Plan:
1. Dr. David Kong's Leadership Development Seminar

### Workshops & Key Learnings:
#### Leadership Development Seminar with Dr. David Kong from the MIT Media Lab:
- Rabbi Hillel's 3 Questions: If I am not for myself, who will be for me? If I am for myself alone, what am I? If not now, when? --> connects to story of self, story of now, and story of us (purpose, urgency, and community)
- Leadership is accepting responsibility for enabling others to achieve shared purpose in the face of uncertainty
- How (strategy analysis aka the head) + Why (story motivation aka the heart) = Mindful Action
- Plot of a story is created through challenge, choice, and outcome, all coinciding with an underlying moral

### Action Item(s):
1. DAY 2 REFLECTION: I loved Dr. Kong's Leadership Development Seminar, especially since it focused on telling our story to find something that we can lead/excel in. Rather than providing us with ways to be a better leader, Dr. Kong's session empowered us to find a reason to push ourselves to be better, which was really inspiring for me. Listening to people's life stories has always interested me, and through this workshop, I got to hear more about my peers' inspiring stories and connect with them. I am excited to apply Dr. Kong's challenges, choices, and outcomes storytelling framework to tell my own story and make a poisitve difference in my community!


<a name = "Day3"></a>
## Day 3: Thursday, July 8, 2021: Introduction to Machine Learning and Scikit-Learn
### Objectives:
1. Introduction to some basic Machine Learning (ML) concepts and models
2. Build ML model development skills

### Lesson Plan:
1. Review Machine Learning models and algorithms using ["An Introduction to Machine Learning Theory and Its Applications: A Visual Tutorial with Examples" article](https://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer)
2. Supplemental Activity: [Your First Machine Learning Model Kaggle Activity on Predicting Housing Prices in Iowa](https://www.kaggle.com/dansbecker/your-first-machine-learning-model)

### Workshops & Key Learnings:
#### Deep Learning Overview with Head Mentors
- Hierarchy: Artificial Intelligence (a cognitive ability that enables the computer to think and mimic actions like humans) --> Machine Learning (a technique which uses statistical models to learn and improve automatically from experience) --> Neural Networks (a subset of ML to analyze different factors and patterns using a network similar to human brain) --> Deep Learning (a richer structure of Neural Networks)
- ML can be applied to all fields i.e. finance (identify fraudulent behavior), healthcare (consumption monitoring), search engines (spam filters), etc.
- The elements of ML include dataset (split into training set, validation set, and testing set), algorithm, and prediction
- The steps of the ML algorithm framework include 1. model training and parameter tuning, model validation and evaluation, and iteration to find the best model (all done using the training set and validation set)
- Supervised vs. Unsupervised Machine Learning
#### Inclusive Leadership with Salila Yohn
- Diversity: everyone has their unique story
- Equity: the idea that acknowledges that not everyone has equal access to opportunities that will help them succeed
- When you don't feel included express your discomfort clearly and calmly
#### Self-Study Applied Deep Learning Curriculum
- "A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance of T, as measured by P, improves with experience E" - Tom Mitchell, Carnegie Mellon University
- Goal of ML: make guesses that are good enough to be useful, not to make "perfect" guesses
- Use neural networks where the number of inputs is large, making the computational cost of handling the problem too overwhelming
- Algorithm types:
  - Regression: fitting linear and non-linear models
  - Clustering: unsupervised classification
  - Decision Trees: tree induction and pruning for both classification and regression tasks
  - Neural Networks: end-to-end training for both classification and regression
  - SVMs: for learning decision boundaries
  - Naive Bayes: direct probabilistic modeling
- Function types: Ensemble Methods, Feature Manipulation, Outlier Detection, and Model Selection and Validation

### Action Item(s):
1. [Scikit-learn Model Development Activity: Iris Decision Tree](https://github.com/rhearjethvani/MITFutureMakers/tree/main/irisDecisionTree)
2. [Predicting Housing Prices in Iowa Kaggle Machine Learning Model Activity](https://github.com/rhearjethvani/MITFutureMakers/tree/main/predictingHousingPricesInIowa)
3. DAY 3 REFLECTION: Today, I got to take a more hands-on approach with Machine Learning models amd code my first algorithm. I) Supervised Machine Learning algorithms are trained on labeled data allowing for extrapolation and are primarily used for classification and regression models, whereas Unsupervised Machine Learning algorithms are trained on unlabeled data to find patterns and relationships and are primarily used for clustering. Supervised ML learns from feedback meaning it can be difficult and time-consuming to label datasets, whereas Unsupervised ML learns from patterns (no feedback) and can have inaccuracies/find irrelevant relationships due to biases in the data. II) The statement "Scikit-Learn has the power to visualize data without a Graphviz, Pandas, or other data analysis libraries" is false because Scikit-Learn is built to model data through supervised and unsupervised machine learning data and requires additional libraries to visualize the data such as Pandas and Graphviz.


<a name = "Day4"></a>
## Day 4: Friday, July 9, 2021: What is Deep Learning?
### Objectives:
1. Become familiar with the differences between AI, Machine Learning, and Deep Learning
2. Introduction to Deep Learning models and algorithms

### Lesson Plan:
1. High-level understanding of Deep Learning models and algorithms using ["A Guide to Deep Learning and Neural Networks" article](https://serokell.io/blog/deep-learning-and-neural-network-guide)
2. Explore ["Whatâ€™s the Difference Between Artificial Intelligence, Machine Learning, and Deep Learning?" article](https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/) to learn more about the differences between the subsets of AI
3. A Quick Dive into the Ethics of AI using ["Ethics in Machine Learning" article](https://towardsdatascience.com/ethics-in-machine-learning-9fa5b1aadc12)

### Workshops & Key Learnings:
#### Deep Learning Overview with Head Mentors
- Traditional Images classification (hand-designed feature extraction algorithms) vs Deep Learning classification (stacking layers that automatically learn more intricate, abstract, and discriminating features and at the end work as a classifier)
- Deep Learning is becoming prevalent now because of availability of data, improved algorithms, and improved technology
- Applications of DL include Computer Vision (CV) and Natural Language Processing (NLP)
- Processing:
  - Central Processing Unit (CPU): tens of operations per cycle (1x1 data unit; scalar)
  - Graphical Processing Unit (GPU): tens of thousands of operations per cycle (1xN data unit; vector)
  - Tensor Processing Unit (TPU): 128,000 operations per cycel (NxN data unit; tensor)
#### Reflection Corner
- Reflected on "Week 1: The Basics" Learnings
#### Self-Study Applied Deep Learning Curriculum
- Artificial Neural Networks (ANNs) - represents the structure of a human brain modeled on the computer, consisting of neurons and synapses organized into layers
- Components of Neural Networks:
  - Neuron/Node - basic unit of neural networks that receives information, performs calculations, and passes it further (each one processes input data to extract a feature, has its own weights that are used to weigh the features, and has an activation function)
    - input neurons - receive information from the outside world
    - hidden neurons - process information
    - output neurons - produce a conclusion
  - Input --> Simple Features --> More Abstract Features --> Mapping from Features --> Output
  - Synapse - connects the neurons; each has a weight (which adds change in the input information)
- Bias - allows for more variations of weights to be stored
- Algorithm Training: iteration (counter that increases every time the neural network goes through one training set), epoch (increases each time we go through the entire set of training sets), or batch (equal to the number of training examples in one forward/backward pass)
- Types of Neural Networks:
  - Feed-Forward Neural Networks - no memory + no going back
  - Recurrent Neural Networks - process texts, videos, or sets of images + become more precise every time because it remembers the results of the previous iteration and can use that information to make better decisions
  - Convolutional Neural Networks - can either be Feed-Forward or Recurrent
  - Generative Adversarial Neural Networks - unsupervised Machine Learning algorithms that combines two neural networks (i.e. Network G generates patterns and Network A tries to distinguish genuine samples from the fake ones)
- Neural Network applications: classification, prediction, and recognition
- Ethics in Machine Learning: bias can be present in the data, algorithm, and/or results

### Action Item(s):
1. DAY 4 REFLECTION: I learned about the ethics of Machine Learning and other issues in the field. I also enjoyed learning about how Deep Learning works (i.e. more in-depth knowledge about CPU, GPU, and TPU). A dataset I found is the [2021 State Government Tax Dataset](https://www.census.gov/data/datasets/2020/econ/stc/2020-annual.html) that can help create models to draw conclusions about the United States economy. By using Machine Learning, we can analyze the effects of the recent American Rescue Plan (including stimulus checks) on the national economy, which is the topic of my current research project.


<a name = "Day5/6"></a>
## Day 5-6: Saturday, July 10-Sunday, July 11, 2021: Weekend

### Key Learnings:
#### Self-Study Applied Deep Learning Curriculum
- Reviewed [Collection of Public Datasets](https://docs.google.com/spreadsheets/d/1qYjOWt39m6r3DpMYx3kespQRVgT6icn5tALXHrztbY4/edit?usp=sharing)

### Action Item(s):
1. DAY 5-6 REFLECTION: Overall, "Week 1: The Basics" was an enjoyable and valuable experience and allowed me to dive further into Deep Learning technology. I am really excited to continue my work during "Week 2: CNNs, Data, & Machine Learning" and to hopefully start building my own Machine Learning models from scratch soon.


<a name = "Day7"></a>
## Day 7: Monday, July 12, 2021: Introduction to ML and TensorFlow
### Objectives:
1. Continue introduction to some basic Machine Learning (ML) concepts and models
2. Build ML model development skills

### Lesson Plan:
1. [The TensorFlow Library](https://www.datacamp.com/community/tutorials/tensorflow-tutorial)
2. [The Keras Library](https://www.datacamp.com/community/tutorials/deep-learning-python?utm_source=adwords_ppc&utm_campaignid=1658343521&utm_adgroupid=63833880615&utm_device=c&utm_keyword=keras&utm_matchtype=p&utm_network=g&utm_adpostion=&utm_creative=319519154328&utm_targetid=aud-299261629654:kwd-295071417107&utm_loc_interest_ms=&utm_loc_physical_ms=9016565&gclid=CjwKCAiAxp-ABhALEiwAXm6IyQJo6LA_Z4HlQUiBhrfFwOFL3Vu0bDTjMI53og6hcZfeWIkzEZRBTxoCzbkQAvD_BwE)
3. [LSTMs for Human Activity Recognition](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition)

### Workshops & Key Learnings:
#### Deep Learning Overview with Head Mentors
- Tensors: multi-dimensional arrays with a uniform type (i.e. floats, ints, complex numbers, and strings)
  - Shape: the length (number of elements) of each of the axes of a tensor
    - Scalar: rank-0 tensor
    - Vector: rank-1 tensor
    - Matrix: rank-2 tensor
    - Cube of Matrices: rank-3 tensor
  - Rank: number of tensor axes
  - Axis/Dimension: a particular dimension of tensor
  - Size: the total number of items in the tensor, the product shape vector
#### Self-Study Applied Deep Learning Curriculum
- TensorFlow uses numerical computations (data flow graphs)
  - Nodes represent mathematical operations
  - Edges represent the data (multidimensional data arrays or tensors that are communicated between the edges)
- Plane Vectors - special types of matrices with one column
  - represented as arrows (have direction and length)
  - find themselves in vector space
- Perceptron (single neuron) vs. Multi-Layer Perceptron
- Tree Structure - input nodes and a single output node which is connected to each input node
  - Input Nodes - each associated with numerical value (any real number)
  - Connections - weight associated with it (any real number)
  - All the connections' weights and input nodes are brought together (used as inputs for a weighted sum)

### Action Item(s):
1. [tensorflowactivity1](link) HERE
2. [kerasactivity1](link) HERE
3. [lstmactivty](link) HERE
4. DAY 7 REFLECTION: I enjoyed learning about Tensorflow, Keras, and PyTorch today. This helped me understand how Machine Learning technology can be applied to various problems. I) Tensors are multi-dimensional arrays with a uniform type such as floats, integers, complex numbers, and strings. Tensors comprise of different shapes (the length of each of the axes of a tensor i.e. scalar: rank-0 tensor, vector: rank-1 tensor, matrix: rank-2 tensor, and cube of matrices: rank-3 tensor), ranks (number of tensor axes), axes/dimensions (a particular dimension of a tensor), and sizes (the total number of items in the tensor, the product shape vector). II) I noticed that the computations in the tutorial are represented in the form of various graphs (i.e. data flow). For example, it is easier to create a graph/plot of data than to reach a formal conclusion about the data (outcome).


<a name = "Day8"></a>
## Day 8: Tuesday, July 13, 2021: What are Neural Networks (NN)?
### Objectives:
1. Deepen understanding of Neural Networks and Deep Learning with real-world examples
2. Further explore the different components and concepts of Neural Networks using a simple NN model

### Lesson Plan:
1. Review ["A Guide to Deep Learning and Neural Networks" article](https://serokell.io/blog/deep-learning-and-neural-network-guide) to learn about the common concepts of Neural Networks and how they work with different ML functions and algorithms

### Workshops & Key Learnings:
#### Deep Learning Overview with Head Mentors
- Artificial Neural Network: consists of a pool of simple processing units, which communicate by sending signals to each other over a large number of weighted connections
  - Processing of ANN: network topology (nodes and connecting lines), adjustment of weights (what is being "learned"), and activation functions
  - ANN functionality (inspired by the human brain):
    - Neuron: the basic computational unit
    - Input Information: travel along the axons and multiplies with the weight (synaptic strength)
    - Dendrites: carry the multiplied signal to the cell body where they all get summed
    - If the final sum is above a certain threshold, the neuron can pass information fed through an activation function
- Activation Function: determines the threshold at which the neuron is activated and the strength of the output signal
  - Step Function: gets triggered above a certain value of the neuron output; else it outputs zero
  - Sign Function: outputs +1 or -1 depending on whether neuron output is greater than zero or not
  - Sigmoid: the S-curve and outputs a value between 0 and 1
- Weights: show the strength of a particular node (initialized with small random values)
- Biases: allow you to shift the activation function curve up or down (provides flexibility)
- Different Dimensions of ANNs
  - When based on the number of hidden layers:
    - Single layer (having one secret layer) --> i.e. single perceptron (the first modern single layer neural network; a linear binary classifer for supervised learning)
    - Multi layer (having multiple secret layers) --> i.e. mulitlayer perceptron (a type of feed-forward artificial neural network that can learn both linear and nonlinear functions; uses backpropogation for training the network; has three kinds of layers: input layer, hidden layers, and output layer)
  - When based on the connection patterns:
    - Feed-Forward: the network doesn't have any memory, which means the ANN graph network does not have a loop
    - Recurrent: the network has memory, allowing it to remember the results of the previous iteration to make better decisions in the current iteration, which means one or more loops occur in the recurrent ANN graph network (has two inputs: the present and the recent past, making it helpful in modeling sequence data)
- Perceptron Functionality
  - 1. All the inputs x are to be multiplied with their weights w
  - 2. Add all the multiplied values and call this the weighted sum
  - 3. Apply that weighted sum to the correct activation function
- 1. Forward Propogation (input layer --> hidden layers --> output layer) --> 2. Error Estimation --> 3. Backward Propogation (output layer --> hidden layers --> input layer)
  - Backpropogation: learning from mistakes (used to optimize the weights of an MLP using the outputs as inputs)
  - Error (supervised learning): the model output differs from the expected output
#### Data as a Product with Eric Weber
- Organizations aren't sure what to expect from data science
- The value of data science depends on who you ask
- Data science is a team sport, but the team is not all data science
- Building for value now conflicts with building for persistent, long-term value
- Data science data product owners are critical
#### Self-Study Applied Deep Learning Curriculum
- Natural Language Processing pipeline: Data collection or assembly --> Data preprocessing --> Feature Extraction --> Model Building --> Model Evaluation

### Action Item(s):
1. [Kaggle XXX](here)
2. DAY 8 REFLECTION: reflection here
