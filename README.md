# MITFutureMakers
SureStart X MIT RAISE


## Breakdown
#### Week 1: The Basics
##### [Day 1: Tuesday, July 6, 2021: Welcome to SureStart! (Getting Started)](#Day1)
##### [Day 2: Wednesday, July 7, 2021: Become a Leader!](#Day2)
##### [Day 3: Thursday, July 8, 2021: Introduction to Machine Learning and Scikit-Learn](#Day3)
##### [Day 4: Friday, July 9, 2021: What is Deep Learning?](#Day4)
##### [Day 5-6: Saturday, July 10-Sunday, July 11, 2021: Weekend](#Day5/6)
#### Week 2: CNNs, Data, & Machine Learning
##### [Day 7: Monday, July 12, 2021: Introduction to ML and TensorFlow](#Day7)
##### [Day 8: Tuesday, July 13, 2021: What are Neural Networks (NN)?](#Day8)
##### [Day 9: Wednesday, July 14, 2021: Intro to Convolutional Neural Networks (CNNs)](#Day9)
##### [Day 10: Thursday, July 15, 2021: Algorithmic Bias and Datasets](#Day10)
##### [Day 11: Friday, July 16, 2021: Neural Network Layers and Continue Practice with MNIST Digits](#Day11)

<a name = "Day1"></a>
## Day 1: Tuesday, July 6, 2021: Welcome to SureStart! (Getting Started)
### Objectives:
1. To get comfortable with the following languages, libraries, and spaces: Python, NumPy, and Github
2. To begin building a technical profile on Github

### Lesson Plan:
1. [MIT FutureMakers Create-a-thon Ramp-Up](https://static1.squarespace.com/static/5f45536caa356e6ab51588f4/t/60c5f9d1311d375de93595e6/1623587288184/MIT+FutureMakers+Ramp+Up.pdf)

### Workshops & Key Learnings:
#### Program Kick-Off:
- [MIT RAISE](raise.mit.edu): a K-12 AI Education initiative @ the Massachusetts Institute of Technology
- With today's information technology, young people have opportunities to create impact on their lives and on their communities --> FutureMakers take Computational Action
- Program Outcome: new tech and "power" skills, a repo of code or app samples, a video of final Create-a-thon Presentation, and more confidence and interest in AI
- Applied Deep Learning Track: learning period from July 6, 2021 to July 30, 2021, and Create-a-thon from August 2, 2021 to August 13, 2021
#### Deep Learning Overview with Head Mentors
- Learned about Python and NumPy in relation to Deep Learning (i.e. list iteration, indexing, broadcasting, etc.
- Jupyter Notebook & Colab Notebook Demos
#### STEM + Computing Reflection Corner for All
- How an interest in computing correlate to different STEM fields and careers
- Not only do the fields utilize logical approaches, they also require creative problem-solving skills and have the power to create something good for our society

### Action Item(s):
1. DAY 1 REFLECTION: I am excited to learn more about AI technology and how to apply this knowledge to help improve the lives of specific demographics of people around me by implementing Deep Learning within my projects. I hope that through the program, I am able to use my passion for Computer Science for societal good.


<a name = "Day2"></a>
## Day 2: Wednesday, July 7, 2021: Become a Leader!
### Objectives:
1. To develop the skills, mindset, and vision of a leader

### Lesson Plan:
1. Dr. David Kong's Leadership Development Seminar

### Workshops & Key Learnings:
#### Leadership Development Seminar with Dr. David Kong from the MIT Media Lab:
- Rabbi Hillel's 3 Questions: If I am not for myself, who will be for me? If I am for myself alone, what am I? If not now, when? --> connects to story of self, story of now, and story of us (purpose, urgency, and community)
- Leadership is accepting responsibility for enabling others to achieve shared purpose in the face of uncertainty
- How (strategy analysis aka the head) + Why (story motivation aka the heart) = Mindful Action
- Plot of a story is created through challenge, choice, and outcome, all coinciding with an underlying moral

### Action Item(s):
1. DAY 2 REFLECTION: I loved Dr. Kong's Leadership Development Seminar, especially since it focused on telling our story to find something that we can lead/excel in. Rather than providing us with ways to be a better leader, Dr. Kong's session empowered us to find a reason to push ourselves to be better, which was really inspiring for me. Listening to people's life stories has always interested me, and through this workshop, I got to hear more about my peers' inspiring stories and connect with them. I am excited to apply Dr. Kong's challenges, choices, and outcomes storytelling framework to tell my own story and make a poisitve difference in my community!


<a name = "Day3"></a>
## Day 3: Thursday, July 8, 2021: Introduction to Machine Learning and Scikit-Learn
### Objectives:
1. Introduction to some basic Machine Learning (ML) concepts and models
2. Build ML model development skills

### Lesson Plan:
1. Review Machine Learning models and algorithms using ["An Introduction to Machine Learning Theory and Its Applications: A Visual Tutorial with Examples" article](https://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer)
2. Supplemental Activity: [Your First Machine Learning Model Kaggle Activity on Predicting Housing Prices in Iowa](https://www.kaggle.com/dansbecker/your-first-machine-learning-model)

### Workshops & Key Learnings:
#### Deep Learning Overview with Head Mentors
- Hierarchy: Artificial Intelligence (a cognitive ability that enables the computer to think and mimic actions like humans) --> Machine Learning (a technique which uses statistical models to learn and improve automatically from experience) --> Neural Networks (a subset of ML to analyze different factors and patterns using a network similar to human brain) --> Deep Learning (a richer structure of Neural Networks)
- ML can be applied to all fields i.e. finance (identify fraudulent behavior), healthcare (consumption monitoring), search engines (spam filters), etc.
- The elements of ML include dataset (split into training set, validation set, and testing set), algorithm, and prediction
- The steps of the ML algorithm framework include 1. model training and parameter tuning, model validation and evaluation, and iteration to find the best model (all done using the training set and validation set)
- Supervised vs. Unsupervised Machine Learning
#### Inclusive Leadership with Salila Yohn
- Diversity: everyone has their unique story
- Equity: the idea that acknowledges that not everyone has equal access to opportunities that will help them succeed
- When you don't feel included express your discomfort clearly and calmly
#### Self-Study Applied Deep Learning Curriculum
- "A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance of T, as measured by P, improves with experience E" - Tom Mitchell, Carnegie Mellon University
- Goal of ML: make guesses that are good enough to be useful, not to make "perfect" guesses
- Use neural networks where the number of inputs is large, making the computational cost of handling the problem too overwhelming
- Algorithm types:
  - Regression: fitting linear and non-linear models
  - Clustering: unsupervised classification
  - Decision Trees: tree induction and pruning for both classification and regression tasks
  - Neural Networks: end-to-end training for both classification and regression
  - SVMs: for learning decision boundaries
  - Naive Bayes: direct probabilistic modeling
- Function types: Ensemble Methods, Feature Manipulation, Outlier Detection, and Model Selection and Validation

### Action Item(s):
1. [Scikit-learn Model Development Activity: Iris Decision Tree](https://github.com/rhearjethvani/MITFutureMakers/tree/main/irisDecisionTree)
2. [Predicting Housing Prices in Iowa Kaggle Machine Learning Model Activity](https://github.com/rhearjethvani/MITFutureMakers/tree/main/predictingHousingPricesInIowa)
3. DAY 3 REFLECTION: Today, I got to take a more hands-on approach with Machine Learning models amd code my first algorithm. I) Supervised Machine Learning algorithms are trained on labeled data allowing for extrapolation and are primarily used for classification and regression models, whereas Unsupervised Machine Learning algorithms are trained on unlabeled data to find patterns and relationships and are primarily used for clustering. Supervised ML learns from feedback meaning it can be difficult and time-consuming to label datasets, whereas Unsupervised ML learns from patterns (no feedback) and can have inaccuracies/find irrelevant relationships due to biases in the data. II) The statement "Scikit-Learn has the power to visualize data without a Graphviz, Pandas, or other data analysis libraries" is false because Scikit-Learn is built to model data through supervised and unsupervised machine learning data and requires additional libraries to visualize the data such as Pandas and Graphviz.


<a name = "Day4"></a>
## Day 4: Friday, July 9, 2021: What is Deep Learning?
### Objectives:
1. Become familiar with the differences between AI, Machine Learning, and Deep Learning
2. Introduction to Deep Learning models and algorithms

### Lesson Plan:
1. High-level understanding of Deep Learning models and algorithms using ["A Guide to Deep Learning and Neural Networks" article](https://serokell.io/blog/deep-learning-and-neural-network-guide)
2. Explore ["What’s the Difference Between Artificial Intelligence, Machine Learning, and Deep Learning?" article](https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/) to learn more about the differences between the subsets of AI
3. A Quick Dive into the Ethics of AI using ["Ethics in Machine Learning" article](https://towardsdatascience.com/ethics-in-machine-learning-9fa5b1aadc12)

### Workshops & Key Learnings:
#### Deep Learning Overview with Head Mentors
- Traditional Images classification (hand-designed feature extraction algorithms) vs Deep Learning classification (stacking layers that automatically learn more intricate, abstract, and discriminating features and at the end work as a classifier)
- Deep Learning is becoming prevalent now because of availability of data, improved algorithms, and improved technology
- Applications of DL include Computer Vision (CV) and Natural Language Processing (NLP)
- Processing:
  - Central Processing Unit (CPU): tens of operations per cycle (1x1 data unit; scalar)
  - Graphical Processing Unit (GPU): tens of thousands of operations per cycle (1xN data unit; vector)
  - Tensor Processing Unit (TPU): 128,000 operations per cycel (NxN data unit; tensor)
#### Reflection Corner
- Reflected on "Week 1: The Basics" Learnings
#### Self-Study Applied Deep Learning Curriculum
- Artificial Neural Networks (ANNs) - represents the structure of a human brain modeled on the computer, consisting of neurons and synapses organized into layers
- Components of Neural Networks:
  - Neuron/Node - basic unit of neural networks that receives information, performs calculations, and passes it further (each one processes input data to extract a feature, has its own weights that are used to weigh the features, and has an activation function)
    - input neurons - receive information from the outside world
    - hidden neurons - process information
    - output neurons - produce a conclusion
  - Input --> Simple Features --> More Abstract Features --> Mapping from Features --> Output
  - Synapse - connects the neurons; each has a weight (which adds change in the input information)
- Bias - allows for more variations of weights to be stored
- Algorithm Training: iteration (counter that increases every time the neural network goes through one training set), epoch (increases each time we go through the entire set of training sets), or batch (equal to the number of training examples in one forward/backward pass)
- Types of Neural Networks:
  - Feed-Forward Neural Networks - no memory + no going back
  - Recurrent Neural Networks - process texts, videos, or sets of images + become more precise every time because it remembers the results of the previous iteration and can use that information to make better decisions
  - Convolutional Neural Networks - can either be Feed-Forward or Recurrent
  - Generative Adversarial Neural Networks - unsupervised Machine Learning algorithms that combines two neural networks (i.e. Network G generates patterns and Network A tries to distinguish genuine samples from the fake ones)
- Neural Network applications: classification, prediction, and recognition
- Ethics in Machine Learning: bias can be present in the data, algorithm, and/or results

### Action Item(s):
1. DAY 4 REFLECTION: I learned about the ethics of Machine Learning and other issues in the field. I also enjoyed learning about how Deep Learning works (i.e. more in-depth knowledge about CPU, GPU, and TPU). A dataset I found is the [2021 State Government Tax Dataset](https://www.census.gov/data/datasets/2020/econ/stc/2020-annual.html) that can help create models to draw conclusions about the United States economy. By using Machine Learning, we can analyze the effects of the recent American Rescue Plan (including stimulus checks) on the national economy, which is the topic of my current research project.


<a name = "Day5/6"></a>
## Day 5-6: Saturday, July 10-Sunday, July 11, 2021: Weekend

### Key Learnings:
#### Self-Study Applied Deep Learning Curriculum
- Reviewed [Collection of Public Datasets](https://docs.google.com/spreadsheets/d/1qYjOWt39m6r3DpMYx3kespQRVgT6icn5tALXHrztbY4/edit?usp=sharing)

### Action Item(s):
1. DAY 5-6 REFLECTION: Overall, "Week 1: The Basics" was an enjoyable and valuable experience and allowed me to dive further into Deep Learning technology. I am really excited to continue my work during "Week 2: CNNs, Data, & Machine Learning" and to hopefully start building my own Machine Learning models from scratch soon.


<a name = "Day7"></a>
## Day 7: Monday, July 12, 2021: Introduction to ML and TensorFlow
### Objectives:
1. Continue introduction to some basic Machine Learning (ML) concepts and models
2. Build ML model development skills

### Lesson Plan:
1. [The TensorFlow Library](https://www.datacamp.com/community/tutorials/tensorflow-tutorial)
2. [The Keras Library](https://www.datacamp.com/community/tutorials/deep-learning-python?utm_source=adwords_ppc&utm_campaignid=1658343521&utm_adgroupid=63833880615&utm_device=c&utm_keyword=keras&utm_matchtype=p&utm_network=g&utm_adpostion=&utm_creative=319519154328&utm_targetid=aud-299261629654:kwd-295071417107&utm_loc_interest_ms=&utm_loc_physical_ms=9016565&gclid=CjwKCAiAxp-ABhALEiwAXm6IyQJo6LA_Z4HlQUiBhrfFwOFL3Vu0bDTjMI53og6hcZfeWIkzEZRBTxoCzbkQAvD_BwE)
3. [LSTMs for Human Activity Recognition](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition)

### Workshops & Key Learnings:
#### Deep Learning Overview with Head Mentors
- Tensors: multi-dimensional arrays with a uniform type (i.e. floats, ints, complex numbers, and strings)
  - Shape: the length (number of elements) of each of the axes of a tensor
    - Scalar: rank-0 tensor
    - Vector: rank-1 tensor
    - Matrix: rank-2 tensor
    - Cube of Matrices: rank-3 tensor
  - Rank: number of tensor axes
  - Axis/Dimension: a particular dimension of tensor
  - Size: the total number of items in the tensor, the product shape vector
#### Self-Study Applied Deep Learning Curriculum
- TensorFlow uses numerical computations (data flow graphs)
  - Nodes represent mathematical operations
  - Edges represent the data (multidimensional data arrays or tensors that are communicated between the edges)
- Plane Vectors - special types of matrices with one column
  - represented as arrows (have direction and length)
  - find themselves in vector space
- Perceptron (single neuron) vs. Multi-Layer Perceptron
- Tree Structure - input nodes and a single output node which is connected to each input node
  - Input Nodes - each associated with numerical value (any real number)
  - Connections - weight associated with it (any real number)
  - All the connections' weights and input nodes are brought together (used as inputs for a weighted sum)
- Using a Recurrent Neural Network (RNN) with Long Short-Term Memory cells (LSTMs) require little to no feature engineering for Human Activity Recognition (HAR) data
  - data can be fed directly into the neural network
  - RNN - takes many input vectors to process them and output other vectors
    - one-to-one vector
    - one-to-many vector
    - many-to-one vector
    - many-to-many vector
  - feature vectors - one vector per time step (converted to a probability vector at the output for classification)

### Action Item(s):
1. [tensorflowactivity1](link) HERE
2. [kerasactivity1](link) HERE
3. [lstmactivty](link) HERE
4. DAY 7 REFLECTION: I enjoyed learning about Tensorflow, Keras, and PyTorch today. This helped me understand how Machine Learning technology can be applied to various problems. I) Tensors are multi-dimensional arrays with a uniform type such as floats, integers, complex numbers, and strings. Tensors comprise of different shapes (the length of each of the axes of a tensor i.e. scalar: rank-0 tensor, vector: rank-1 tensor, matrix: rank-2 tensor, and cube of matrices: rank-3 tensor), ranks (number of tensor axes), axes/dimensions (a particular dimension of a tensor), and sizes (the total number of items in the tensor, the product shape vector). II) I noticed that the computations in the tutorial are represented in the form of various graphs (i.e. data flow). For example, it is easier to create a graph/plot of data than to reach a formal conclusion about the data (outcome).


<a name = "Day8"></a>
## Day 8: Tuesday, July 13, 2021: What are Neural Networks (NN)?
### Objectives:
1. Deepen understanding of Neural Networks and Deep Learning with real-world examples
2. Further explore the different components and concepts of Neural Networks using a simple NN model

### Lesson Plan:
1. Review ["A Guide to Deep Learning and Neural Networks" article](https://serokell.io/blog/deep-learning-and-neural-network-guide) to learn about the common concepts of Neural Networks and how they work with different ML functions and algorithms

### Workshops & Key Learnings:
#### Deep Learning Overview with Head Mentors
- Artificial Neural Network: consists of a pool of simple processing units, which communicate by sending signals to each other over a large number of weighted connections
  - Processing of ANN: network topology (nodes and connecting lines), adjustment of weights (what is being "learned"), and activation functions
  - ANN functionality (inspired by the human brain):
    - Neuron: the basic computational unit
    - Input Information: travel along the axons and multiplies with the weight (synaptic strength)
    - Dendrites: carry the multiplied signal to the cell body where they all get summed
    - If the final sum is above a certain threshold, the neuron can pass information fed through an activation function
- Activation Function: determines the threshold at which the neuron is activated and the strength of the output signal
  - Step Function: gets triggered above a certain value of the neuron output; else it outputs zero
  - Sign Function: outputs +1 or -1 depending on whether neuron output is greater than zero or not
  - Sigmoid: the S-curve and outputs a value between 0 and 1
- Weights: show the strength of a particular node (initialized with small random values)
- Biases: allow you to shift the activation function curve up or down (provides flexibility)
- Different Dimensions of ANNs
  - When based on the number of hidden layers:
    - Single layer (having one secret layer) --> i.e. single perceptron (the first modern single layer neural network; a linear binary classifer for supervised learning)
    - Multi layer (having multiple secret layers) --> i.e. mulitlayer perceptron (a type of feed-forward artificial neural network that can learn both linear and nonlinear functions; uses backpropogation for training the network; has three kinds of layers: input layer, hidden layers, and output layer)
  - When based on the connection patterns:
    - Feed-Forward: the network doesn't have any memory, which means the ANN graph network does not have a loop
    - Recurrent: the network has memory, allowing it to remember the results of the previous iteration to make better decisions in the current iteration, which means one or more loops occur in the recurrent ANN graph network (has two inputs: the present and the recent past, making it helpful in modeling sequence data)
- Perceptron Functionality
  - 1. All the inputs x are to be multiplied with their weights w
  - 2. Add all the multiplied values and call this the weighted sum
  - 3. Apply that weighted sum to the correct activation function
- 1. Forward Propogation (input layer --> hidden layers --> output layer) --> 2. Error Estimation --> 3. Backward Propogation (output layer --> hidden layers --> input layer)
  - Backpropogation: learning from mistakes (used to optimize the weights of an MLP using the outputs as inputs)
  - Error (supervised learning): the model output differs from the expected output
#### Data as a Product with Eric Weber
- Organizations aren't sure what to expect from data science
- The value of data science depends on who you ask
- Data science is a team sport, but the team is not all data science
- Building for value now conflicts with building for persistent, long-term value
- Data science data product owners are critical
#### Self-Study Applied Deep Learning Curriculum
- Natural Language Processing pipeline: Data collection or assembly --> Data preprocessing --> Feature Extraction --> Model Building --> Model Evaluation

### Action Item(s):
1. [Sarcasm Detection Activity Using News Headlines Dataset](https://github.com/rhearjethvani/MITFutureMakers/tree/main/sarcasmDetection)
2. DAY 8 REFLECTION: I struggled a little bit with debugging the Sarcasm Detection Activity, but learned a lot about training the model to optimize/make it more efficiency. During the Deep Learning Overview session, I was particularly intrigued by the different choices of Artificial Neural Networks and learning about which is more suitable for what situation. I also enjoyed Mr. Weber's talk on "Data as a Product" since it gave me insight on the job-market applications of data/AI!


<a name = "Day9"></a>
## Day 9: Wednesday, July 14, 2021: Intro to Convolutional Neural Netowrks (CNNs)
### Objectives:
1. Introduction to Convolutional Neural Networks (CNNs), a very popular type of Neural Network
2. Become acquainted with model evaluation metrics
3. Become familiar with the effect of training data size on a model's predictive power

### Lesson Plan:
1. Learn about CNNs using ["Convolutional Neural Networks Cheatsheet"](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks) notebook
2. Visualize how CNNs work with handwritten digits using ["2D Visualization of a Convolutional Neural Network"](https://www.cs.ryerson.ca/~aharley/vis/conv/flat.html) demonstration
3. Learn about Confusion Matrices in Machine Learning using ["What is a Confusion Matrix in Machine Learning"](https://machinelearningmastery.com/confusion-matrix-machine-learning/) article

### Workshops & Key Learnings:
#### Deep Learning Overview with Head Mentors
- Convolutional Neural Network (CNN): type of feed-forward artificial neural network
  - Performs a linear operation called "convolution" between input data and feature extractor filter
  - Most successful/widely used application of CNN is analyzing visual images and videos (i.e. object classification, object detection, and localization)
  - Four types of layers:
    - Convolution (CONV) Layer: an element-wise matrix multiplication (dot product) occurs between the pixel value with filter size, the kernal moves left to right calculating the dot product, then summed resulting in a single value, and all the single values of the dot product create a feature map
    - Activation Layer (Rectified Linear United Layer aka ReLU): used after the feature maps are extracted to learn more complex features; no parameters or weights are given to learn from images and all the negative pixel values to 0, introducing non-linearity to the network and resulting in a rectified feature map
    - Pooling Layer: the rectified feature map goes through a down-sampling (shriking) operation that reduces the dimensionality of the feature map and reduces the computational complexity, making it easier to identify relevant information of the image such as edges, corners, and curves
      - Max pooling: the largest element is taken from the feature map
      - Average pooling: calculates the average of the elements in a predefined size image section
    - Fully-Connected Layer:
  - CNN Operation: when the computer sees an image, it finds a number of pixel intensity (represented in the form of pixel intensity --> represented in the form of array)
#### App Inventor Track Talk with Dr. Hae Won Park
- Do long-term robot companions need socio-emotive intelligence? How will it affect us in long-term real-world contexts?
- Increasing inclusiveness through personalization for each individual user
- Inequality of education --> early childhood education is a key time to intervene
- Learning is cognitive, social, affective, and relational
  - Interaction with social robots activates social thinking
- Socio-emotive relational AI
  - Socio-emotive perception: machine perception of interpersonal cues
  - Socio-emotive expression: expressive cues that reveal "state of mind"
  - Socio-emotive learning: learn via social interaction and observation
  - Socio-emotive relationship: build rapport and emotional bond as attentive, empathic other
#### Self-Study Applied Deep Learning Curriculum
- Convolutional Neural Networks Cheatsheet
  - Architecture of a Traditional CNN
    - Input image
    - Convolutions (CONV): uses filters that perform convolution operations as it is scanning the input I with respect to its dimensions (hyperparameters include the filter size F and stride S; resulting output O is called feature map or activation map)
    - Pooling (POOL): a downsampling operation, which does some spatial invariance
      - Max Pooling: each pooling operation selects the maximum value of the current view
      - Average Pooling: each pooling operation averages the value of the current view
    - Fully Connected (FC): operates on a flattened input where ach  input is connected to all neurons
  - Filter Hyperparameters: dimensions of a filter, stride, and zero-padding
    - Tuned through parameter compatibility in Convolution layer, understanding the complexity of the model, and receptive field
  - Commonly used Activation Functions: Rectified Linear Unit (ReLU) and Softmax
  - Object Detection
    - Types of models: Image Classification (classifies a picture and predicts probability of object using a traditional CNN), Classification with Localization (detects an object in a picture and predicts probability of object and where it is located using simplified YOLO or R-CNN), and detection (detects up to several objects in a picture and predicts probabilities of objects and where they are located using YOLO or R-CNN)
    - Detection methods: Bounding Box (detects the part of the image where the object is located), Landmark (detects a shape or characteristics of an object; more granular), Intersection over Union (a function that quantifies how correctly positioned a predicted bounding box is over the actual bounding box), Anchor Boxes (technique used to predict overlapping bounding boxes), and Non-Max Suppression (aims at removing duplicate overlapping bounding boxes of a same object by electing the most representative ones)
   - You Only Look Once (YOLO): object detection algorithm that divides the input image into a GxG grid, (for each grid cell) runs a CNN that predicts y of the form, and runs the non-max suppression algorithm to remove any potential duplicate overlapping bounding boxes
   - Region with Convolutional Neural Networks (R-CNN): object detection algorithm that first segments the image to find potential relevant bounding boxes and then runs the detection algorithm to find most probable objects in those bounding boxes
   - Face Verification (one-to-one lookup) and Recognition (one-to-many lookup)
    - One Shot Learning
    - Siamese Network
    - Triplet Loss
   - Neural Style Transfer: motivation, activation, content cost function, style matrix, style cost function, and overall cost function
   - Architectures using Computational Tricks
    - Generative Adversarial Network (GANs): composed of a generative and a discriminative model where the generative model aims at generating the most truthful output that will be fed into the discriminative which aims at differentiating the generated and true image
    - Residual Network (ResNet): uses residual blocks with a high number of layers meant to decrease the training error
    - Inception Network: uses inception modules and aims at giving a try at different convolutions in order to increase its performance through features diversification
- What is a Confusion Matrix in Machine Learning?
  - Confusion Matrix: a technique for summarizing the performance of a classification algorithm
  - Classification Accuracy: the ratio of correct predictions to total predictions made

### Action Item(s):
1. [MNIST Classification Activity](https://github.com/rhearjethvani/MITFutureMakers/tree/main/mnistClassification)
2. DAY 9 REFLECTION: I am happy that I was able to tinker with the MNIST dataset and explore its real-word applications while working on the MNIST Digits Classification activity. I also learned a lot about the architectures of Convolutional Neural Networks (CNNs) such as the different layers, hyperparameters, and operation. Dr. Hae Won Park's talk on Socio-Emotive Relational AI was really interesting and I would definitely like to further explore the long-term impacts of robot companions.


<a name = "Day10"></a>
## Day 10: Thursday, July 15, 2021: Algorithmic Bias and Datasets
### Objectives:
1. Become cognizant of algorithmic bias in some AI-based software, the reasons for its occurence, and its effects on real-world inequalities and biases
2. Think critically about the dangers that society might face, if automated systems have biases

### Lesson Plan:
1. Review the Stanford and Google AI interactive presentation, ["Bias in the Vision and Language of Artificial Intelligence"](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/slides/cs224n-2019-lecture19-bias.pdf), about algorithmic bias with vision and language applications of AI

### Workshops & Key Learnings:
#### Deep Learning Overview with Head Mentors
- AI Bias: the underlying prejudice in data that's used to create AI algorithms, which can ultimately result in discrimination and other social consequences
- Causes of Bias: the outputs produced by Machine Learning models and AI systems are simply a reflection of the training datasets they are exposed to
  - Personal Bias vs Environmental Bias
- Types of Bias: Sample Bias, Exclusion Bias, Measurement Bias, Observer Bias, Association Bias, and Recall Bias
- Considerations for a non-biased algorithm
  - The data that one uses needs to represent "what should be" and not "what is"
  - Some sort of data governance should be mandated and enforced
  - Model Evaluation should include generalization across groups
 - Solution: diversity
#### Set & Achieve Your Goals with Carly Chase & Laura Castaing
- Step 1: What is my ideal outcome?
- Step 2: What have I already done?
- Step 3: Where am I stopped?
- Step 4: How could I get unstopped?
- Step 5: When will I realistically do this?
#### Self-Study Applied Deep Learning Curriculum
- Bias in the Vision and Language of Artificial Intelligence
  - Training data are collected and annotated --> model is trained --> media are filtered, ranked, aggregated, or generated --> people see output --> feedback loop
  - Prototype Theory: one purpose of categorization is to reduce the infinite differences among stimuli to behaviorally and cognitively usable proportions
  - Human Reporting Bias: the frequency with which people write about actions, outcomes, or properties is not a reflection of real-world frequencies or the degree to which a property is characteristic of a class of individuals
  - Biases in Data
    - Selection Bias: selection does not reflect a random sample
    - Out-Group Homogeneity Bias: tendancy to see outgroup members as more alike than ingroup members
    - Leads to biased data representation, biased labels, and biased interpretations
  - Biases in Interpretation
    - Confirmation Bias: the tendancy to search for, interpret, favor, and recall information in a way that confirms preexisting beliefs
    - Overgeneralization: coming to a conclusion based on information that is too general and/or not specific enough
    - Correlation Fallacy: confusing correlation with causation
    - Automation Bias: propensity for humans to favor suggestions from automated decision-making systems over contradictory information without automation
  - "Bias" can be good, bad, or neutral
  - Evaluate for Fairness and Inclusion
    - Disaggregated Evaluation
    - Intersectional Evaluation
    - Confusion Matrix
  - Use ML techniques for bias mitigation and inclusion
- Why Should I Care About DEI?
  - No company runs without people
  - Everyone has identities that you are required to support
- Gender Shades
  - Automated systems are not inherently neutral
  - Reflect the priorities, preferences, and prejudices of those who have the power to mold AI

### Action Item(s):
1. Play [Survival of the Best Fit Game](https://www.survivalofthebestfit.com/) to learn more about how AI might impact human resources and hiring processes in different fields
2. Watch ["Why Should I Care About DEI (Diversity, Equity, and Inclusion)?" Video](https://www.youtube.com/watch?v=yqIpPwkpXXc) to understand why it is important for everyone to think about the significance of DEI in different environments
3. Read ["Gender Shades" Article](http://gendershades.org/overview.html) and discuss some of the ways to avoid algorithmic bias when constructing AI projects
4. DAY 10 REFLECTION: AI Ethics has always been a topic of interest for me, especially with the increasing prevalence in our society. I'm happy I got to explore the more technical side of why these biases are present. I) I think Machine Learning and AI concepts were utilized in the design of the Survival of the Best Fit game through the oversimplification of composite data characteristics. II) A real-world example of a biased machine learning model is male vs female gender stereotyping. For example, most ML models think of a male when they read in "doctor" or "engineer." Some potential ways to make this model more fair, inclusive, and equitable include exposing the model to more female datasets and adding more layers to the architecture.


<a name = "Day11"></a>
## Day 11: Friday, July 16, 2021: Neural Network Layers and Continue Practice with MNIST Digits
### Objectives:
1. Gain an understanding of the different types of layers and their roles in a CNN architecture
2. Learn how to classify handwritten digits (specifically, the MNIST dataset) using different structures of CNNs and how those structures produce improved results
3. Reflect on how different CNN architectures interact with the same dataset to produce improved results

### Lesson Plan:
1. Become familiar with the different CNN layers (i.e. Convolution, Pooling, and Fully Connected) using the [CNN Architecture Guide](https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939)
2. Complete the introductory dataset practice to learn how to classify handwritten digts with varying model depth and width using ["How to classify MNIST digits with different neural network architectures" article](https://medium.com/tebs-lab/how-to-classify-mnist-digits-with-different-neural-network-architectures-39c75a0f03e3)

### Workshops & Key Learnings:
#### Deep Learning Overview with Head Mentors
- Convolutional Neural Network (CNN): type of feed-forward Artificial Neural Network
  - Convolution (CONV) Layer: feature extraction layer that extracts the discriminating feature of the given input
  - Activation Layer: introduces nonlinearity to the network to help the model generalize (usually use ReLU)
  - Pooling Layer: a down-sampling layer that selects the most relevant features
  - Fully Connected Layer: combines the features from previous layers to get it ready for classification
- CNN Operation: Input (batch size + kernal size) --> feature extractor (convolutional layers: # of kernels, pooling layer, etc.) --> classifier (fully-connected layers with feed-forward layer and # of neurons)
  - Feature Extractor: convolution layer followed by an activation layer (ReLU) and a pooling layer; separates and identifies various features of the image
  - Classifier: a fully-connected layer utilizing the extracted features of previous stages from the convolution and the pooling operation and predicts the class
- Flattening: convers the 2-dimensional output of pooling (i.e. the feature map) into a single linear vector
  - Takes the numbers row by row and concatenates them to form a long feature vector
- Output feature map: result of applying a filter to an image (or in case of an N-layer CNN, an input feature map)
  - Depth: number of filters used for the convolution operation
  - Stride: decides by what step the kernel will move throughout the input image (moving the filters in the input matrix)
  - Padding: the input matrix is added with zeros around the border matrix
- MNIST classification steps
  - Prepare and load the dataset
  - Perform data preprocessing (i.e. scale the dataset)
  - Select a ML model (i.e. CNN) and define its architecture
  - Specify loss function and model optimizer
  - Split the dataset into training and validation sets
  - Train and validate the model; repeat this step until you see the accuracy increasing
  - Evaluate the final set of model parameters with test dataset
#### Reflection Corner
- Reflected on "Week 2: CNNs, Data, & Machine Learning" Learnings
#### Self-Study Applied Deep Learning Curriculum
- Convolutional Neural Networks, Explained
  - Specializes in processing data that has a grid-like topology (i.e. images, enabling sight to computers)
  - Architecture
    - Convolution Layer: performs a dot product between two matrices, where one matrix is the set of learnable parameters otherwise known as a kernel and the other matrix is the restricted portion of the receptive field
    - Pooling Layer: replaces the output of the network at certain locations by deriving a summary statistic of the nearby outputs
    - Fully Connected Layer: neurons in this layer have full connectivity with all neurons in the preceding and succeeding layer
    - Non-Linearity Layers:
      - Sigmoid: takes a real-valued number and “squashes” it into a range between 0 and 1
      - Tanh: squashes a real-valued number to the range [-1, 1]
      - Rectified Linear Unit (ReLU): activation is simply threshold at zero
  - Applications of CNN: Object Detection, Semantic Segmentation, Image Captioning, etc.
- MNIST digit classification with different neural network architectures
  - x input data
  - y labels
  - ŷ predictions made by a model
  - Training data (data our model learns from)
  - Test data (kept secret from the model until after it has been train; used to evaluate our model)
  - Loss function (quantifies how accurate a model’s predictions were)
  - Optimization algorithm (controls exactly how the weights of the computational graph are adjusted during training)

### Action Item(s):
1. [MNIST Neural Network Activity](https://github.com/rhearjethvani/MITFutureMakers/tree/main/mnistClassification)
2. [Classifying MNIST Datasets CNN](https://github.com/rhearjethvani/MITFutureMakers/tree/main/classifyingMNISTDatasetsCNN)
3. DAY 11 REFLECTION: The in-depth explanation of the CNN layers today was really helpful. I was able to better understand the workings of a neural network and the necessary components for the model to be trained. I) [list the differences]


<a name = "Day12/13"></a>
## Day 5-6: Saturday, July 10-Sunday, July 11, 2021: Weekend

### Key Learnings:
#### Self-Study Applied Deep Learning Curriculum
- here

### Action Item(s):
1. DAY 5-6 REFLECTION: here


<a name = "Day14"></a>
## Day 12: Friday, July 16, 2021: HERE
### Objectives:
1. here

### Lesson Plan:
1. Learn about CNNs using ["here"](here) notebook

### Workshops & Key Learnings:
#### Deep Learning Overview with Head Mentors
- here
#### Workshop HERE
- here
#### Self-Study Applied Deep Learning Curriculum
- here?

### Action Item(s):
1. [activity name](activitygithublink)
2. DAY 11 REFLECTION: reflection here
